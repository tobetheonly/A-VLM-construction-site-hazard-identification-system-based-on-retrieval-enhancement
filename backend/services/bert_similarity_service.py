import os
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import Dict, Tuple
from config import Config

# é…ç½® Hugging Face é•œåƒæºï¼ˆå¦‚æœåœ¨ä¸­å›½å¤§é™†ï¼Œå¯ä»¥ä½¿ç”¨é•œåƒï¼‰
# å¦‚æœé‡åˆ° SSL é”™è¯¯æˆ–è¿æ¥é—®é¢˜ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥ä½¿ç”¨é•œåƒæº
#os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'  # ä½¿ç”¨ Hugging Face é•œåƒ


class BertSimilarityService:
    """BERTè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—æœåŠ¡"""
    
    def __init__(self):
        # ä½¿ç”¨ä¸­æ–‡BERTæ¨¡å‹
        print("ğŸ”„ æ­£åœ¨åŠ è½½BERTæ¨¡å‹...")
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æœ¬åœ°æ¨¡å‹
        local_model_paths = [
            './models/paraphrase-multilingual-MiniLM-L12-v2',
            './models/distiluse-base-multilingual-cased-v1',
            os.path.expanduser('~/.cache/huggingface/hub/models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2'),
        ]
        
        # æ¨¡å‹åŠ è½½ç­–ç•¥ï¼šæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæ¨¡å‹
        # å…ˆå°è¯•æœ¬åœ°è·¯å¾„ï¼Œå†å°è¯•åœ¨çº¿ä¸‹è½½
        model_candidates = []
        
        # æ·»åŠ æœ¬åœ°æ¨¡å‹è·¯å¾„
        for local_path in local_model_paths:
            if os.path.exists(local_path):
                model_candidates.append(local_path)
                print(f"ğŸ“ å‘ç°æœ¬åœ°æ¨¡å‹: {local_path}")
        
        # æ·»åŠ åœ¨çº¿æ¨¡å‹ï¼ˆå¦‚æœæœ¬åœ°æ²¡æœ‰ï¼‰
        if not model_candidates:
            model_candidates.extend([
                'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                'paraphrase-multilingual-MiniLM-L12-v2',
                'sentence-transformers/distiluse-base-multilingual-cased-v1',
                'distiluse-base-multilingual-cased-v1',
            ])
        
        self.model = None
        last_error = None
        
        for model_name in model_candidates:
            try:
                print(f"ğŸ”„ å°è¯•åŠ è½½æ¨¡å‹: {model_name}")
                self.model = SentenceTransformer(model_name)
                print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}")
                break
            except Exception as e:
                last_error = e
                error_msg = str(e)
                print(f"âš ï¸  æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {error_msg[:100]}...")
                
                # å¦‚æœæ˜¯ SSL é”™è¯¯ï¼Œç»™å‡ºç‰¹æ®Šæç¤º
                if 'SSL' in error_msg or 'SSLError' in error_msg:
                    print("ğŸ’¡ æç¤º: æ£€æµ‹åˆ° SSL è¿æ¥é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ã€‚")
                    print("   è§£å†³æ–¹æ¡ˆ:")
                    print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                    print("   2. å¦‚æœåœ¨ä¸­å›½å¤§é™†ï¼Œå¯ä»¥é…ç½®é•œåƒæº:")
                    print("      åœ¨ä»£ç ä¸­å–æ¶ˆæ³¨é‡Š: os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'")
                    print("   3. æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°")
                continue
        
        if self.model is None:
            error_msg = f"âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½éƒ½å¤±è´¥äº†ã€‚æœ€åä¸€ä¸ªé”™è¯¯: {last_error}"
            print(error_msg)
            print("\n" + "="*60)
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®:")
            print("="*60)
            print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¡®è®¤èƒ½å¦è®¿é—® https://hf-mirror.com")
            print("2. å¦‚æœç½‘ç»œå—é™ï¼Œå¯ä»¥:")
            print("   - ä½¿ç”¨ VPN æˆ–ä»£ç†")
            print("   - æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ï¼ˆæ¨èï¼‰")
            print("   - ä¸´æ—¶ç¦ç”¨ SSL éªŒè¯ï¼ˆä¸å®‰å…¨ï¼Œä»…ç”¨äºæµ‹è¯•ï¼‰")
            print("3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ­¥éª¤:")
            print("   a) è®¿é—®: https://hf-mirror.com/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
            print("   b) ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•")
            print("   c) ä¿®æ”¹ä»£ç ä½¿ç”¨æœ¬åœ°è·¯å¾„: SentenceTransformer('./models/paraphrase-multilingual-MiniLM-L12-v2')")
            print("="*60)
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­è¿è¡Œï¼ˆå¦‚æœ BERT ä¸æ˜¯å¿…éœ€çš„ï¼‰
            print("\nâš ï¸  è­¦å‘Š: ç¨‹åºæ— æ³•ç»§ç»­è¿è¡Œï¼Œå› ä¸º BERT æ¨¡å‹æ˜¯å¿…éœ€çš„ã€‚")
            raise RuntimeError(
                "æ— æ³•åŠ è½½ BERT æ¨¡å‹ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ã€‚\n"
                "è¯¦ç»†è§£å†³æ–¹æ¡ˆè¯·æŸ¥çœ‹ä¸Šæ–¹çš„æç¤ºä¿¡æ¯ã€‚"
            )
        
        print("âœ… BERTæ¨¡å‹åŠ è½½å®Œæˆ")
        
        # åŠ è½½éšæ‚£ç±»åˆ«æè¿°
        self.hazard_descriptions = self._load_hazard_descriptions()
        # é¢„ç¼–ç æ‰€æœ‰ç±»åˆ«æè¿°
        self.description_embeddings = self._encode_descriptions()
    
    def _load_hazard_descriptions(self) -> Dict[str, str]:
        """åŠ è½½éšæ‚£ç±»åˆ«æè¿°æ–‡æ¡£"""
        descriptions = {}
        description_file = Config.CATEGORY_FILE
        
        try:
            if os.path.exists(description_file):
                with open(description_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if ':' in line and line:
                            parts = line.split(':', 1)
                            if len(parts) == 2:
                                hazard_type = parts[0].strip()
                                description = parts[1].strip()
                                if description:
                                    descriptions[hazard_type] = description
                print(f"âœ… åŠ è½½äº† {len(descriptions)} ä¸ªéšæ‚£ç±»åˆ«æè¿°")
            else:
                print(f"âš ï¸  æè¿°æ–‡ä»¶ä¸å­˜åœ¨: {description_file}")
        except Exception as e:
            print(f"âŒ åŠ è½½æè¿°æ–‡ä»¶å¤±è´¥: {e}")
        
        return descriptions
    
    def _encode_descriptions(self) -> Dict[str, np.ndarray]:
        """é¢„ç¼–ç æ‰€æœ‰éšæ‚£ç±»åˆ«æè¿°"""
        embeddings = {}
        description_texts = []
        type_keys = []
        
        for hazard_type, description in self.hazard_descriptions.items():
            description_texts.append(description)
            type_keys.append(hazard_type)
        
        if description_texts:
            # æ‰¹é‡ç¼–ç æé«˜æ•ˆç‡
            encoded = self.model.encode(description_texts, convert_to_numpy=True)
            for i, hazard_type in enumerate(type_keys):
                embeddings[hazard_type] = encoded[i]
        
        return embeddings
    
    def calculate_similarity(
        self, 
        generated_description: str, 
        hazard_type: str
    ) -> Tuple[float, str]:
        """
        è®¡ç®—ç”Ÿæˆçš„æè¿°ä¸å¯¹åº”ç±»å‹æ ‡å‡†æè¿°çš„ç›¸ä¼¼åº¦
        
        Args:
            generated_description: å¤§æ¨¡å‹ç”Ÿæˆçš„éšæ‚£æè¿°
            hazard_type: éšæ‚£ç±»å‹ï¼ˆå¦‚ "1", "2"ï¼‰
        
        Returns:
            (ç›¸ä¼¼åº¦åˆ†æ•°, æ ‡å‡†æè¿°æ–‡æœ¬)
        """
        try:
            # è·å–æ ‡å‡†æè¿°
            standard_description = self.hazard_descriptions.get(hazard_type)
            if not standard_description:
                print(f"âš ï¸  æœªæ‰¾åˆ°ç±»å‹ {hazard_type} çš„æ ‡å‡†æè¿°")
                return 0.0, ""
            
            # ç¼–ç ç”Ÿæˆçš„æè¿°
            generated_embedding = self.model.encode(
                [generated_description], 
                convert_to_numpy=True
            )[0]
            
            # è·å–é¢„ç¼–ç çš„æ ‡å‡†æè¿°
            standard_embedding = self.description_embeddings.get(hazard_type)
            if standard_embedding is None:
                # å¦‚æœé¢„ç¼–ç ä¸­æ²¡æœ‰ï¼Œå®æ—¶ç¼–ç 
                standard_embedding = self.model.encode(
                    [standard_description], 
                    convert_to_numpy=True
                )[0]
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = cosine_similarity(
                generated_embedding.reshape(1, -1),
                standard_embedding.reshape(1, -1)
            )[0][0]
            
            # ç¡®ä¿ç›¸ä¼¼åº¦åœ¨ [0, 1] èŒƒå›´å†…
            similarity = max(0.0, min(1.0, float(similarity)))
            
            return similarity, standard_description
            
        except Exception as e:
            print(f"âŒ è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0, ""
    
    def get_average_similarity(self) -> Dict[str, float]:
        """è·å–æ‰€æœ‰å·²è¯†åˆ«å›¾åƒçš„å¹³å‡ç›¸ä¼¼åº¦"""
        from pymongo import MongoClient
        from config import Config
        
        try:
            client = MongoClient(Config.MONGODB_URI)
            db = client[Config.DATABASE_NAME]
            cache_collection = db.analysis_cache
            
            # è·å–æ‰€æœ‰æœ‰ç›¸ä¼¼åº¦è®°å½•çš„ç»“æœ
            all_results = list(cache_collection.find(
                {"result.bert_similarity": {"$exists": True}}
            ))
            
            if not all_results:
                return {
                    "average": 0.0,
                    "count": 0,
                    "by_model": {}
                }
            
            # è®¡ç®—æ€»ä½“å¹³å‡
            similarities = [
                r["result"].get("bert_similarity", 0.0) 
                for r in all_results
            ]
            average = sum(similarities) / len(similarities) if similarities else 0.0
            
            # æŒ‰æ¨¡å‹åˆ†ç»„è®¡ç®—
            by_model = {}
            for model in ['gemini', 'gpt4o']:
                model_results = [
                    r["result"].get("bert_similarity", 0.0)
                    for r in all_results
                    if r.get("model") == model and r["result"].get("bert_similarity")
                ]
                if model_results:
                    by_model[model] = sum(model_results) / len(model_results)
                else:
                    by_model[model] = 0.0
            
            return {
                "average": average,
                "count": len(all_results),
                "by_model": by_model
            }
        except Exception as e:
            print(f"âŒ è·å–å¹³å‡ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return {
                "average": 0.0,
                "count": 0,
                "by_model": {}
            }