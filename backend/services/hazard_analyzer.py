import os
import json
import base64
import re
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from services.tfidf_similarity_service import TfidfSimilarityService
from services.clip_service import CLIPService
from services.llm_service import LLMService
from services.bert_similarity_service import BertSimilarityService
from utils.image_processor import ImageProcessor
from config import Config


class HazardAnalyzer:
    """éšæ‚£åˆ†æå™¨ - æ•´åˆCLIPæ¨¡å‹ã€LLMæœåŠ¡å’Œç›¸ä¼¼æ¡ˆä¾‹æ£€ç´¢"""

    def __init__(self, llm_service: LLMService):
        self.llm_service = llm_service
        self.clip_service = CLIPService()
        self.image_processor = ImageProcessor()
        self.bert_similarity = BertSimilarityService()  # åˆå§‹åŒ–BERTç›¸ä¼¼åº¦æœåŠ¡
        self.tfidf_similarity = TfidfSimilarityService()

        # éšæ‚£ç±»å‹æ˜ å°„
        self.hazard_types = {
            "1": "æœªæŒ‰è§„å®šç©¿æˆ´åå…‰å®‰å…¨æœ",
            "2": "é«˜å¤„ä½œä¸šæœªæ­£ç¡®ä½¿ç”¨å®‰å…¨å¸¦",
            "3": "é…ç”µç®±æœªåŠæ—¶é”é—­",
            "4": "æœªæŒ‰è§„å®šé…ç½®ç­ç«å™¨ã€æ¶ˆé˜²è®¾æ–½ç­‰",
            "5": "ç°åœºé˜²æŠ¤æ ç­‰å®‰å…¨é˜²æŠ¤è®¾æ–½ç¼ºå¤±ã€ç ´æŸæˆ–è®¾ç½®ä¸è§„èŒƒ",
            "6": "è®¾å¤‡å®‰å…¨é˜²æŠ¤è®¾æ–½ã€è£…ç½®ç¼ºå¤±æˆ–å¤±æ•ˆ",
            "7": "èµ·é‡åŠè£…è®¾å¤‡é’¢ä¸ç»³ç£¨æŸã€æ–­ä¸ä¸¥é‡ï¼Œæ­æ¥é•¿åº¦ä¸è¶³",
            "8": "æ±½è½¦åŠã€éšè½¦åŠã€æ³µè½¦æ”¯è…¿æœªå…¨éƒ¨ä¼¸å‡ºã€æœªå«æ•æœ¨è¿›è¡Œä½œä¸š",
            "9": "åŸºå‘æ”¯æŠ¤æªæ–½ä¸åˆ°ä½",
            "10": "ç­ç«å™¨æœªæŒ‰è§„å®šè¦æ±‚æ”¾ç½®",
            "11": "æœªæŒ‰è§„å®šè®¾ç½®æ¥åœ°çº¿æˆ–æ¥åœ°ä¸è‰¯",
            "12": "å®‰å…¨è­¦ç¤ºæ ‡å¿—æ ‡è¯†ç¼ºå¤±æˆ–è®¾ç½®ä¸è§„èŒƒ",
            "13": "ç­ç«å™¨å‹åŠ›ä¸è¶³ï¼Œç­ç«å™¨ã€æ¶ˆé˜²è®¾æ–½ç­‰æœªæŒ‰è§„å®šè¿›è¡Œæ£€æŸ¥ã€ç»´æŠ¤",
            "14": "ä¸ç¬¦åˆä¸‰çº§é…ç”µä¸¤çº§æ¼ç”µä¿æŠ¤ã€ä¸€æœºä¸€é—¸ä¸€æ¼ä¸€ç®±è¦æ±‚",
            "15": "ç”µç¼†å¤–çš®ç ´æŸæˆ–æ•·è®¾ä¸è§„èŒƒ",
        }

    def analyze_hazard(
        self,
        image_path: str,
        top_k: int = 5,
        few_shot_count: int = 3,
        provider: str = "gemini",
    ) -> Dict:
        """åˆ†æéšæ‚£å›¾ç‰‡ï¼Œå¯æŒ‡å®š provider=gemini/gpt4o"""
        try:
            print(f"ğŸ” å¼€å§‹åˆ†æå›¾ç‰‡: {image_path}")

            # 1. å¤„ç†å›¾ç‰‡
            processed_image = self.image_processor.process_image(image_path)

            # 2. CLIP ç›´æ¥åˆ†ç±»
            direct_classification = self.clip_service.classify_hazard(processed_image)
            print(
                f"âœ… CLIPç›´æ¥åˆ†ç±»ç»“æœ: ç±»å‹ {direct_classification['type']}, ç½®ä¿¡åº¦ {direct_classification['confidence']:.3f}"
            )

            # 3. æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹
            similar_cases = self.clip_service.find_similar_cases(
                processed_image, top_k=top_k
            )
            print(f"ğŸ“‹ æ‰¾åˆ° {len(similar_cases)} ä¸ªç›¸ä¼¼æ¡ˆä¾‹")

            # 4. Few-shot ç¤ºä¾‹
            few_shot_examples = self.clip_service.get_random_examples(
                count=few_shot_count
            )
            print(f"ğŸ¯ è·å– {len(few_shot_examples)} ä¸ªFew-shotç¤ºä¾‹")

            # 5. å›¾ç‰‡è½¬ base64
            image_base64 = self.image_processor.image_to_base64(processed_image)

            # 6. è°ƒç”¨ LLMï¼ˆå¯åˆ‡æ¢æ¨¡å‹ï¼‰
            enhanced_result = self.llm_service.generate_hazard_analysis(
                image_base64=image_base64,
                similar_cases=similar_cases,
                few_shot_examples=few_shot_examples,
                provider=provider,
            )
            print("#####################llmè¾“å‡ºç»“æœ########################")
            print(enhanced_result)
            
            # æ¸…ç† markdown ä»£ç å—æ ‡è®°
            cleaned_result = enhanced_result.strip()
            # åˆ é™¤ ```json æˆ– ``` å¼€å¤´çš„æ ‡è®°
            cleaned_result = re.sub(r'^```(?:json)?\s*\n?', '', cleaned_result)
            # åˆ é™¤ç»“å°¾çš„ ``` æ ‡è®°
            cleaned_result = re.sub(r'\n?```\s*$', '', cleaned_result)
            cleaned_result = cleaned_result.strip()
            
            print("#####################æ¸…ç†åçš„llmè¾“å‡ºç»“æœ########################")
            print(cleaned_result)

            # 7. æ•´åˆç»“æœï¼ˆå¸¦ä¸Š modelï¼‰
            final_result = self._integrate_results(
                direct_classification=direct_classification,
                enhanced_result=cleaned_result,
                similar_cases=similar_cases,
                model=provider,
            )

            print(
                f"ğŸ‰ åˆ†æå®Œæˆ: ç±»å‹ {final_result['type']}, ç½®ä¿¡åº¦ {final_result['confidence']:.3f}, BERTç›¸ä¼¼åº¦ {final_result.get('bert_similarity', 0.0):.4f}"
            )
            return final_result

        except Exception as e:
            print(f"âŒ éšæ‚£åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._create_error_result(str(e), model=provider)

    def _integrate_results(
        self,
        direct_classification: Dict,
        enhanced_result: str,
        similar_cases: List,
        model: str,
    ) -> Dict:
        """æ•´åˆç›´æ¥åˆ†ç±»å’Œå¢å¼ºåˆ†æç»“æœ"""
        try:
            enhanced_data = None
            
            # å¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„ enhanced_result
            if isinstance(enhanced_result, str):
                try:
                    enhanced_data = json.loads(enhanced_result)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  JSONè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹å†…å®¹: {enhanced_result[:200]}...")
                    enhanced_data = None
            else:
                enhanced_data = enhanced_result

            if enhanced_data and isinstance(enhanced_data, Dict):
                result = {
                    "id": f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "type": enhanced_data.get("type", direct_classification["type"]),
                    "description": enhanced_data.get(
                        "description", direct_classification["description"]
                    ),
                    "suggestion": enhanced_data.get(
                        "suggestion",
                        self._get_default_suggestion(direct_classification["type"]),
                    ),
                    "confidence": enhanced_data.get(
                        "confidence", direct_classification["confidence"]
                    ),
                    "similar_cases": [
                        case.get("description", "") for case in similar_cases[:3]
                    ],
                    "analysis_method": "CLIP + LLM Enhanced",
                    "model": model,
                    "created_at": datetime.now().isoformat(),
                }
            else:
                result = {
                    "id": f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "type": direct_classification["type"],
                    "description": direct_classification["description"],
                    "suggestion": self._get_default_suggestion(
                        direct_classification["type"]
                    ),
                    "confidence": direct_classification["confidence"],
                    "similar_cases": [
                        case.get("description", "") for case in similar_cases[:3]
                    ],
                    "analysis_method": "CLIP Direct Classification",
                    "model": model,
                    "created_at": datetime.now().isoformat(),
                }

            # è®¡ç®—BERTç›¸ä¼¼åº¦ï¼ˆå¯¹æ‰€æœ‰ç»“æœéƒ½è®¡ç®—ï¼‰
            hazard_type = result["type"]
            generated_desc = result["description"]
            
            try:
                similarity, standard_desc = self.bert_similarity.calculate_similarity(
                    generated_desc, hazard_type
                )
                result["bert_similarity"] = similarity
                result["standard_description"] = standard_desc
                print(f"ğŸ“Š BERTç›¸ä¼¼åº¦: {similarity:.4f} (ç±»å‹ {hazard_type})")
            except Exception as e:
                print(f"âš ï¸  è®¡ç®—BERTç›¸ä¼¼åº¦å¤±è´¥: {e}")
                result["bert_similarity"] = 0.0
                result["standard_description"] = ""
            # æ·»åŠ  TF-IDF ç›¸ä¼¼åº¦è®¡ç®—
            try:
                tfidf_sim, _ = self.tfidf_similarity.calculate_similarity(
                    generated_desc, hazard_type
                )
                result["tfidf_similarity"] = tfidf_sim
                print(f"ğŸ“Š TF-IDFç›¸ä¼¼åº¦: {tfidf_sim:.4f} (ç±»å‹ {hazard_type})")
            except Exception as e:
                print(f"âš ï¸  è®¡ç®—TF-IDFç›¸ä¼¼åº¦å¤±è´¥: {e}")
                result["tfidf_similarity"] = 0.0

            return result

        except Exception as e:
            print(f"âš ï¸  ç»“æœæ•´åˆå¤±è´¥ï¼Œä½¿ç”¨ç›´æ¥åˆ†ç±»ç»“æœ: {e}")
            import traceback
            traceback.print_exc()
            
            result = {
                "id": f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "type": direct_classification["type"],
                "description": direct_classification["description"],
                "suggestion": self._get_default_suggestion(
                    direct_classification["type"]
                ),
                "confidence": direct_classification["confidence"],
                "similar_cases": [
                    case.get("description", "") for case in similar_cases[:3]
                ],
                "analysis_method": "CLIP Direct Classification (Fallback)",
                "model": model,
                "created_at": datetime.now().isoformat(),
            }
            
            # å³ä½¿fallbackä¹Ÿè®¡ç®—ç›¸ä¼¼åº¦
            try:
                hazard_type = result["type"]
                generated_desc = result["description"]
                similarity, standard_desc = self.bert_similarity.calculate_similarity(
                    generated_desc, hazard_type
                )
                result["bert_similarity"] = similarity
                result["standard_description"] = standard_desc
            except Exception as e:
                print(f"âš ï¸  Fallbackæ—¶è®¡ç®—BERTç›¸ä¼¼åº¦å¤±è´¥: {e}")
                result["bert_similarity"] = 0.0
                result["standard_description"] = ""
            # æ·»åŠ  TF-IDF è®¡ç®—
            try:
                tfidf_sim, _ = self.tfidf_similarity.calculate_similarity(
                    generated_desc, hazard_type
                )
                result["tfidf_similarity"] = tfidf_sim
            except Exception as e:
                print(f"âš ï¸  Fallbackæ—¶è®¡ç®—TF-IDFç›¸ä¼¼åº¦å¤±è´¥: {e}")
                result["tfidf_similarity"] = 0.0
            
            return result

    def _get_default_suggestion(self, hazard_type: str) -> str:
        """è·å–é»˜è®¤æ•´æ”¹å»ºè®®"""
        suggestions = {
            "1": "ç«‹å³åœæ­¢ä½œä¸šï¼Œè¦æ±‚æ‰€æœ‰äººå‘˜æŒ‰è§„å®šç©¿æˆ´åå…‰å®‰å…¨æœå’Œå®‰å…¨å¸½ï¼Œå¹¶è¿›è¡Œå®‰å…¨æ•™è‚²åŸ¹è®­",
            "2": "ç«‹å³åœæ­¢é«˜ç©ºä½œä¸šï¼Œè¦æ±‚ä½œä¸šäººå‘˜æ­£ç¡®ä½©æˆ´å®‰å…¨å¸¦ï¼Œå¹¶è®¾ç½®æ°´å¹³å®‰å…¨ç»³ç­‰é˜²æŠ¤æªæ–½",
            "3": "ç«‹å³å…³é—­é…ç”µç®±å¹¶ä¸Šé”ï¼Œæ£€æŸ¥é…ç”µç®±é˜²æŠ¤è®¾æ–½ï¼Œç¡®ä¿ç¬¦åˆå®‰å…¨è§„èŒƒ",
            "4": "ç«‹å³é…ç½®ç¬¦åˆè¦æ±‚çš„ç­ç«å™¨å’Œæ¶ˆé˜²è®¾æ–½ï¼Œå¹¶å®šæœŸæ£€æŸ¥ç»´æŠ¤",
            "5": "ç«‹å³ä¿®å¤æˆ–é‡æ–°è®¾ç½®é˜²æŠ¤æ ç­‰å®‰å…¨é˜²æŠ¤è®¾æ–½ï¼Œç¡®ä¿å…¶å®Œæ•´æœ‰æ•ˆ",
            "6": "ç«‹å³ä¿®å¤æˆ–æ›´æ¢è®¾å¤‡å®‰å…¨é˜²æŠ¤è®¾æ–½ï¼Œç¡®ä¿æ‰€æœ‰é˜²æŠ¤è£…ç½®æ­£å¸¸å·¥ä½œ",
            "7": "ç«‹å³æ›´æ¢ç£¨æŸä¸¥é‡çš„é’¢ä¸ç»³ï¼Œç¡®ä¿æ­æ¥é•¿åº¦ç¬¦åˆè§„èŒƒè¦æ±‚",
            "8": "ç«‹å³è°ƒæ•´æ”¯è…¿ä½¿å…¶å…¨éƒ¨ä¼¸å‡ºå¹¶å«å¥½æ•æœ¨ï¼Œç¡®ä¿è®¾å¤‡ç¨³å®šä½œä¸š",
            "9": "ç«‹å³å®Œå–„åŸºå‘æ”¯æŠ¤æªæ–½ï¼Œç¡®ä¿åŸºå‘å®‰å…¨ç¨³å®š",
            "10": "ç«‹å³å°†ç­ç«å™¨æŒ‰è§„å®šè¦æ±‚æ”¾ç½®ï¼Œå¹¶å®šæœŸæ£€æŸ¥ç»´æŠ¤",
            "11": "ç«‹å³è®¾ç½®æˆ–ä¿®å¤æ¥åœ°çº¿ï¼Œç¡®ä¿æ¥åœ°è‰¯å¥½",
            "12": "ç«‹å³è¡¥å……ç¼ºå¤±çš„å®‰å…¨è­¦ç¤ºæ ‡å¿—ï¼Œå¹¶è§„èŒƒè®¾ç½®ä½ç½®",
            "13": "ç«‹å³æ›´æ¢å‹åŠ›ä¸è¶³çš„ç­ç«å™¨ï¼Œå»ºç«‹å®šæœŸæ£€æŸ¥ç»´æŠ¤åˆ¶åº¦",
            "14": "ç«‹å³æ•´æ”¹é…ç”µç³»ç»Ÿï¼Œç¡®ä¿ç¬¦åˆä¸‰çº§é…ç”µä¸¤çº§æ¼ç”µä¿æŠ¤è¦æ±‚",
            "15": "ç«‹å³ä¿®å¤ç ´æŸç”µç¼†ï¼Œè§„èŒƒç”µç¼†æ•·è®¾ï¼Œç¡®ä¿ç”¨ç”µå®‰å…¨",
        }
        return suggestions.get(
            hazard_type,
            f"é’ˆå¯¹éšæ‚£ç±»å‹{hazard_type}ï¼Œè¯·ç«‹å³æ•´æ”¹ç›¸å…³å®‰å…¨éšæ‚£ï¼Œç¡®ä¿ç¬¦åˆå®‰å…¨è§„èŒƒè¦æ±‚",
        )

    def _create_error_result(
        self, error_message: str, model: Optional[str] = None
    ) -> Dict:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            "id": f"error_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "type": "unknown",
            "description": f"åˆ†æå¤±è´¥: {error_message}",
            "suggestion": "è¯·æ£€æŸ¥å›¾ç‰‡è´¨é‡æˆ–é‡æ–°ä¸Šä¼ å›¾ç‰‡",
            "confidence": 0.0,
            "similar_cases": [],
            "analysis_method": "Error",
            "model": model or "unknown",
            "created_at": datetime.now().isoformat(),
            "error": error_message,
            "bert_similarity": 0.0,
            "standard_description": "",
        }

    def batch_analyze(self, image_paths: List[str], top_k: int = 5) -> List[Dict]:
        """æ‰¹é‡åˆ†æå¤šå¼ å›¾ç‰‡"""
        results = []
        for i, image_path in enumerate(image_paths, 1):
            print(f"ğŸ”„ æ‰¹é‡åˆ†æè¿›åº¦: {i}/{len(image_paths)} - {image_path}")
            try:
                result = self.analyze_hazard(image_path, top_k=top_k)
                results.append(result)
            except Exception as e:
                error_result = self._create_error_result(str(e))
                error_result["image_path"] = image_path
                results.append(error_result)
        return results

    def get_analysis_statistics(self) -> Dict:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        try:
            return {
                "total_analyzed": 0,
                "success_rate": 0.0,
                "average_confidence": 0.0,
                "most_common_type": None,
                "last_updated": datetime.now().isoformat(),
            }
        except Exception as e:
            return {
                "error": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}",
                "last_updated": datetime.now().isoformat(),
            }

    def validate_image(self, image_path: str) -> Tuple[bool, str]:
        """éªŒè¯å›¾ç‰‡æ˜¯å¦é€‚åˆåˆ†æ"""
        try:
            if not os.path.exists(image_path):
                return False, "å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨"

            file_size = os.path.getsize(image_path)
            if file_size > Config.MAX_CONTENT_LENGTH:
                return (
                    False,
                    f"å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ï¼Œè¶…è¿‡{Config.MAX_CONTENT_LENGTH / 1024 / 1024:.1f}MBé™åˆ¶",
                )

            valid_extensions = [
                ".png",
                ".jpg",
                ".jpeg",
                ".PNG",
                ".JPG",
                ".JPEG",
            ]
            file_ext = os.path.splitext(image_path)[1]
            if file_ext not in valid_extensions:
                return False, f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {file_ext}"

            if not self.image_processor.validate_image(image_path):
                return False, "æ— æ•ˆçš„å›¾ç‰‡æ–‡ä»¶"

            return True, "å›¾ç‰‡éªŒè¯é€šè¿‡"

        except Exception as e:
            return False, f"å›¾ç‰‡éªŒè¯å¤±è´¥: {e}"


