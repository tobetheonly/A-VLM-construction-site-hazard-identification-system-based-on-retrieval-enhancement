import os
import json
import re
import sys
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)
from datetime import datetime
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure, DuplicateKeyError
from config import Config
from services.clip_service import CLIPService
from utils.image_processor import ImageProcessor

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“å’Œç´¢å¼•"""
    try:
        # è¿æ¥MongoDB
        client = MongoClient(Config.MONGODB_URI, serverSelectionTimeoutMS=5000)
        
        # æµ‹è¯•è¿æ¥
        client.admin.command('ping')
        print("âœ… MongoDBè¿æ¥æˆåŠŸ")
        
        db = client[Config.DATABASE_NAME]
        
        # åˆ›å»ºé›†åˆ
        cases_collection = db.cases
        
        # åˆ é™¤ç°æœ‰ç´¢å¼•ï¼ˆå¦‚æœéœ€è¦é‡æ–°åˆ›å»ºï¼‰
        # cases_collection.drop_indexes()
        
        # åˆ›å»ºç´¢å¼•
        cases_collection.create_index("type")
        cases_collection.create_index("filename")
        cases_collection.create_index("image_id")
        cases_collection.create_index([("type", 1), ("image_id", 1)], unique=True)
        
        # åˆ›å»ºæ–‡æœ¬æœç´¢ç´¢å¼•
        cases_collection.create_index([
            ("description", "text"),
            ("category_description", "text")
        ])
        
        print("âœ… æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ")
        
        # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        stats = db.command("collStats", "cases")
        print(f"ğŸ“Š å½“å‰casesé›†åˆæ–‡æ¡£æ•°é‡: {stats.get('count', 0)}")
        
        return db
        
    except ConnectionFailure as e:
        print(f"âŒ MongoDBè¿æ¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿MongoDBæœåŠ¡æ­£åœ¨è¿è¡Œ")
        return None
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def load_hazard_descriptions():
    """åŠ è½½éšæ‚£æè¿°æ–‡æ¡£"""
    description_file = "datasets/éšæ‚£æ•°æ®é›†/éšæ‚£æ•°æ®é›†/éšæ‚£æè¿°æ–‡æ¡£.txt"
    category_file = "datasets/éšæ‚£æ•°æ®é›†/éšæ‚£æ•°æ®é›†/éšæ‚£ç±»åˆ«æè¿°æ–‡æ¡£.txt"
    
    descriptions = {}
    categories = {}
    
    # åŠ è½½ç±»åˆ«æè¿°
    try:
        if os.path.exists(category_file):
            with open(category_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if ':' in line and line:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            category_id = parts[0].strip()
                            category_desc = parts[1].strip()
                            if category_desc:  # ç¡®ä¿æè¿°ä¸ä¸ºç©º
                                categories[category_id] = category_desc
            print(f"âœ… åŠ è½½äº† {len(categories)} ä¸ªéšæ‚£ç±»åˆ«")
        else:
            print(f"âš ï¸  ç±»åˆ«æè¿°æ–‡ä»¶ä¸å­˜åœ¨: {category_file}")
    except Exception as e:
        print(f"âŒ åŠ è½½ç±»åˆ«æè¿°å¤±è´¥: {e}")
    
    # åŠ è½½è¯¦ç»†æè¿°
    try:
        if os.path.exists(description_file):
            with open(description_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if '-' in line and ':' in line and line:
                        # è§£ææ ¼å¼: 1-1:æè¿°å†…å®¹
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            image_key = parts[0].strip()
                            description = parts[1].strip()
                            if description:  # ç¡®ä¿æè¿°ä¸ä¸ºç©º
                                descriptions[image_key] = description
            print(f"âœ… åŠ è½½äº† {len(descriptions)} ä¸ªè¯¦ç»†æè¿°")
        else:
            print(f"âš ï¸  è¯¦ç»†æè¿°æ–‡ä»¶ä¸å­˜åœ¨: {description_file}")
    except Exception as e:
        print(f"âŒ åŠ è½½è¯¦ç»†æè¿°å¤±è´¥: {e}")
    
    return descriptions, categories

def load_dataset():
    """åŠ è½½æ•°æ®é›†åˆ°æ•°æ®åº“"""
    # åˆå§‹åŒ–æ•°æ®åº“
    db = init_database()
    if db is None:
        return
    try:
        # åŠ è½½æè¿°æ–‡æ¡£
        descriptions, categories = load_hazard_descriptions()
        
        # åˆå§‹åŒ–æœåŠ¡
        print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–CLIPæœåŠ¡...")
        clip_service = CLIPService()
        image_processor = ImageProcessor()
        
        # å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        image_folder = "datasets/éšæ‚£æ•°æ®é›†/éšæ‚£æ•°æ®é›†/éšæ‚£å›¾ç‰‡"
        
        if not os.path.exists(image_folder):
            print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {image_folder}")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = [f for f in os.listdir(image_folder) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'))]
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        
        loaded_count = 0
        updated_count = 0
        error_count = 0
        skipped_count = 0
        
        for i, filename in enumerate(image_files, 1):
            try:
                print(f"ğŸ”„ å¤„ç†è¿›åº¦: {i}/{len(image_files)} - {filename}")
                
                # è§£ææ–‡ä»¶åè·å–ç±»å‹å’Œç¼–å·
                name_without_ext = os.path.splitext(filename)[0]
                parts = name_without_ext.split('-')
                
                if len(parts) >= 2:
                    hazard_type = parts[0]
                    image_id = parts[1]
                    
                    image_path = os.path.join(image_folder, filename)
                    
                    # éªŒè¯å›¾ç‰‡æ–‡ä»¶
                    if not image_processor.validate_image(image_path):
                        print(f"âš ï¸  æ— æ•ˆå›¾ç‰‡æ–‡ä»¶: {filename}")
                        error_count += 1
                        continue
                    
                    # å¤„ç†å›¾ç‰‡
                    processed_image = image_processor.process_image(image_path)
                    
                    # æå–ç‰¹å¾å‘é‡
                    features = clip_service.encode_image(processed_image)
                    
                    # æ„å»ºæè¿°é”®ï¼ˆæ ¼å¼: 1-1ï¼‰
                    desc_key = f"{hazard_type}-{image_id}"
                    description = descriptions.get(desc_key, f"éšæ‚£ç±»å‹{hazard_type}çš„ç¤ºä¾‹å›¾ç‰‡")
                    category_desc = categories.get(hazard_type, f"éšæ‚£ç±»å‹{hazard_type}")
                    
                    # å­˜å‚¨åˆ°æ•°æ®åº“
                    case_data = {
                        'filename': filename,
                        'type': hazard_type,
                        'image_id': image_id,
                        'features': features.tolist(),
                        'description': description,
                        'category_description': category_desc,
                        'suggestion': generate_suggestion(hazard_type, category_desc),
                        'image_path': image_path,
                        'created_at': datetime.now(),
                        'updated_at': datetime.now(),
                        'file_size': os.path.getsize(image_path),
                        'file_type': os.path.splitext(filename)[1].lower()
                    }
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = db.cases.find_one({'filename': filename})
                    if existing:
                        # æ›´æ–°ç°æœ‰è®°å½•
                        case_data['created_at'] = existing.get('created_at', datetime.now())
                        db.cases.update_one(
                            {'filename': filename}, 
                            {'$set': case_data}
                        )
                        updated_count += 1
                        print(f"ğŸ”„ å·²æ›´æ–°: {filename}")
                    else:
                        # æ’å…¥æ–°è®°å½•
                        db.cases.insert_one(case_data)
                        loaded_count += 1
                        print(f"âœ… å·²åŠ è½½: {filename}")
                    
                else:
                    print(f"âš ï¸  æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: {filename}")
                    error_count += 1
                    
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
                error_count += 1
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        print(f"\nğŸ“Š æ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"âœ… æˆåŠŸåŠ è½½: {loaded_count} ä¸ªæ–‡ä»¶")
        print(f"ğŸ”„ æ›´æ–°æ–‡ä»¶: {updated_count} ä¸ªæ–‡ä»¶")
        print(f"âŒ é”™è¯¯æ–‡ä»¶: {error_count} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡
        total_docs = db.cases.count_documents({})
        print(f"ğŸ“ˆ æ•°æ®åº“ä¸­æ€»æ–‡æ¡£æ•°: {total_docs}")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        pipeline = [
            {"$group": {"_id": "$type", "count": {"$sum": 1}}},
            {"$sort": {"_id": 1}}
        ]
        type_stats = list(db.cases.aggregate(pipeline))
        print("ğŸ“‹ æŒ‰ç±»å‹ç»Ÿè®¡:")
        for stat in type_stats:
            print(f"   ç±»å‹ {stat['_id']}: {stat['count']} ä¸ªæ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")

def generate_suggestion(hazard_type, category_desc):
    """æ ¹æ®éšæ‚£ç±»å‹ç”Ÿæˆæ•´æ”¹å»ºè®®"""
    suggestions = {
        "1": "ç«‹å³åœæ­¢ä½œä¸šï¼Œè¦æ±‚æ‰€æœ‰äººå‘˜æŒ‰è§„å®šç©¿æˆ´åå…‰å®‰å…¨æœå’Œå®‰å…¨å¸½ï¼Œå¹¶è¿›è¡Œå®‰å…¨æ•™è‚²åŸ¹è®­",
        "2": "ç«‹å³åœæ­¢é«˜ç©ºä½œä¸šï¼Œè¦æ±‚ä½œä¸šäººå‘˜æ­£ç¡®ä½©æˆ´å®‰å…¨å¸¦ï¼Œå¹¶è®¾ç½®æ°´å¹³å®‰å…¨ç»³ç­‰é˜²æŠ¤æªæ–½",
        "3": "ç«‹å³å…³é—­é…ç”µç®±å¹¶ä¸Šé”ï¼Œæ£€æŸ¥é…ç”µç®±é˜²æŠ¤è®¾æ–½ï¼Œç¡®ä¿ç¬¦åˆå®‰å…¨è§„èŒƒ",
        "4": "ç«‹å³é…ç½®ç¬¦åˆè¦æ±‚çš„ç­ç«å™¨å’Œæ¶ˆé˜²è®¾æ–½ï¼Œå¹¶å®šæœŸæ£€æŸ¥ç»´æŠ¤",
        "5": "ç«‹å³ä¿®å¤æˆ–é‡æ–°è®¾ç½®é˜²æŠ¤æ ç­‰å®‰å…¨é˜²æŠ¤è®¾æ–½ï¼Œç¡®ä¿å…¶å®Œæ•´æœ‰æ•ˆ",
        "6": "ç«‹å³ä¿®å¤æˆ–æ›´æ¢è®¾å¤‡å®‰å…¨é˜²æŠ¤è®¾æ–½ï¼Œç¡®ä¿æ‰€æœ‰é˜²æŠ¤è£…ç½®æ­£å¸¸å·¥ä½œ",
        "7": "ç«‹å³æ›´æ¢ç£¨æŸä¸¥é‡çš„é’¢ä¸ç»³ï¼Œç¡®ä¿æ­æ¥é•¿åº¦ç¬¦åˆè§„èŒƒè¦æ±‚",
        "8": "ç«‹å³è°ƒæ•´æ”¯è…¿ä½¿å…¶å…¨éƒ¨ä¼¸å‡ºå¹¶å«å¥½æ•æœ¨ï¼Œç¡®ä¿è®¾å¤‡ç¨³å®šä½œä¸š",
        "9": "ç«‹å³å®Œå–„åŸºå‘æ”¯æŠ¤æªæ–½ï¼Œç¡®ä¿åŸºå‘å®‰å…¨ç¨³å®š",
        "10": "ç«‹å³å°†ç­ç«å™¨æŒ‰è§„å®šè¦æ±‚æ”¾ç½®ï¼Œå¹¶å®šæœŸæ£€æŸ¥ç»´æŠ¤",
        "11": "ç«‹å³è®¾ç½®æˆ–ä¿®å¤æ¥åœ°çº¿ï¼Œç¡®ä¿æ¥åœ°è‰¯å¥½",
        "12": "ç«‹å³è¡¥å……ç¼ºå¤±çš„å®‰å…¨è­¦ç¤ºæ ‡å¿—ï¼Œå¹¶è§„èŒƒè®¾ç½®ä½ç½®",
        "13": "ç«‹å³æ›´æ¢å‹åŠ›ä¸è¶³çš„ç­ç«å™¨ï¼Œå»ºç«‹å®šæœŸæ£€æŸ¥ç»´æŠ¤åˆ¶åº¦",
        "14": "ç«‹å³æ•´æ”¹é…ç”µç³»ç»Ÿï¼Œç¡®ä¿ç¬¦åˆä¸‰çº§é…ç”µä¸¤çº§æ¼ç”µä¿æŠ¤è¦æ±‚",
        "15": "ç«‹å³ä¿®å¤ç ´æŸç”µç¼†ï¼Œè§„èŒƒç”µç¼†æ•·è®¾ï¼Œç¡®ä¿ç”¨ç”µå®‰å…¨"
    }
    
    return suggestions.get(hazard_type, f"é’ˆå¯¹{category_desc}ï¼Œè¯·ç«‹å³æ•´æ”¹ç›¸å…³å®‰å…¨éšæ‚£ï¼Œç¡®ä¿ç¬¦åˆå®‰å…¨è§„èŒƒè¦æ±‚")

def cleanup_database():
    """æ¸…ç†æ•°æ®åº“ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
    try:
        db = init_database()
        if db is not None:
            result = db.cases.delete_many({})
            print(f"ğŸ—‘ï¸  å·²æ¸…ç† {result.deleted_count} ä¸ªæ–‡æ¡£")
    except Exception as e:
        print(f"âŒ æ¸…ç†æ•°æ®åº“å¤±è´¥: {e}")

def backup_database():
    """å¤‡ä»½æ•°æ®åº“"""
    try:
        import shutil
        from datetime import datetime
        
        backup_dir = f"backups/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(backup_dir, exist_ok=True)
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ å¤‡ä»½é€»è¾‘
        print(f"ğŸ“¦ å¤‡ä»½å·²ä¿å­˜åˆ°: {backup_dir}")
    except Exception as e:
        print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ–MongoDBæ•°æ®åº“...")
    
    # å¯é€‰ï¼šæ¸…ç†ç°æœ‰æ•°æ®
    # cleanup_database()
    
    # åˆå§‹åŒ–å¹¶åŠ è½½æ•°æ®
    load_dataset()
    
    print("ğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")