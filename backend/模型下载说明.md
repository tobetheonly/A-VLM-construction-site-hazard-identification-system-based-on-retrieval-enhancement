# BERT 模型下载说明

## 问题说明

如果遇到 SSL 连接错误，无法自动下载模型，可以手动下载模型到本地。

## 方法一：使用 Python 脚本下载（最推荐）⭐

如果 Git LFS 下载失败（DNS 解析错误），使用此方法：

```bash
cd backend
python download_model.py
```

**优点：**
- 自动处理镜像源
- 支持断点续传
- 错误提示清晰
- 不需要 Git LFS

## 方法二：使用 Git LFS 下载

⚠️ **注意：** 如果遇到 `no such host` 错误，说明镜像站的 LFS 服务器无法访问，请使用方法一。

### 1. 安装 Git LFS
```bash
# Windows: 下载并安装 Git for Windows (已包含 Git LFS)
# 或单独安装: https://git-lfs.github.com/

# 验证安装
git lfs version
```

### 2. 克隆模型仓库
```bash
# 创建模型目录
mkdir -p backend/models
cd backend/models

# 使用镜像站克隆模型
git lfs install
git clone https://hf-mirror.com/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
```

**如果遇到 DNS 错误：**
- 错误信息: `lookup cas-bridge.xethub.hf-mirror.org: no such host`
- 解决方案: 使用上面的 Python 脚本下载（方法一）

## 方法三：手动下载文件

### 1. 访问模型页面
- 镜像站: https://hf-mirror.com/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
- 官方站: https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

### 2. 下载必需文件
需要下载以下文件到 `backend/models/paraphrase-multilingual-MiniLM-L12-v2/` 目录：

- `config.json`
- `modules.json`
- `1_Pooling/config.json`
- `2_Dense/config.json` (如果存在)
- `pytorch_model.bin` 或 `model.safetensors`
- `tokenizer.json`
- `tokenizer_config.json`
- `vocab.txt` (如果存在)

### 3. 目录结构
```
backend/
  models/
    paraphrase-multilingual-MiniLM-L12-v2/
      config.json
      modules.json
      pytorch_model.bin
      tokenizer.json
      tokenizer_config.json
      1_Pooling/
        config.json
```

## 方法四：从浏览器手动下载（如果所有方法都失败）

如果 Python 脚本和 Git LFS 都失败，可以从浏览器手动下载：

## 验证

下载完成后，重新运行应用，程序会自动检测并使用本地模型。

## 注意事项

1. 模型文件较大（约 400-500 MB），请确保有足够的磁盘空间
2. 如果使用镜像站下载，确保网络连接稳定
3. 下载完成后，可以删除在线下载的代码，直接使用本地路径

